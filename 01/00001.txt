01.txt

机器学习
一、人工智能、机器学习与深度学习
人工智能
       机器学习
              经典机器学习
              基于神经网络的机器学习
                     浅层学习
                     深层学习(深度学习)
              强化学习
              迁移学习
2->   ->4
3->   ->6
2.1->   ->4.2
1.9->   -> ? 3.8
二、机器学习基本类型
1.有监督学习：根据已知的输入和输出，建立联系它们的模型，根据该模型对未知输出的输入进行判断。
1)回归：以无限连续域的形式表示输出。
2)分类：以有限离散域的形式表示输出。
2.无监督学习：在一组没有已知输出(标签)的输入中，根据数据的内部特征和联系，找到某种规则，进行族群的划分——聚类。
3.半监督学习：从一个相对有限的已知结构中利用有监督学习的方法，构建基本模型，通过对未知输入和已知输入的比对，判断其输出，扩展原有的已知领域。

4.机器学习的挑战
1)训练数据不足
2)训练数据不具代表性
3)训练数据质量不佳
4)混在无关特征
5)过拟合和欠拟合

5.测试和验证
数据集 --训练集
		\验证集(调参数)
		\测试集

6.机器学习和人工智能
人工智能
	机器学习
		传统机器学习,
		深度学习
	...


一、机器学习的基本流程
1.数据采集
特征
  |
 V
姓名  年龄  专业  成绩  方向         月收入
张飞  24    电子   90    人工智能  8000    <- 样本
赵云  22    历史   80    网络应用  7000
...
|<-----------输入------------->|<-输出->|
2.数据预处理(清洗)
3.建立学习模型
4.训练学习模型
5.测试学习模型
6.验证学习模型
7.复用学习模型
二、数据预处理
1.均值移除：将样本中各个列的平均值和标准差处理为0和1
代码：std.py
2.范围缩放：将样本中各个列的最大值和最小值统一到给定值，其它数据按相同的比例缩放
代码：mms.py
3.归一化：将样本中各个行中的元素除以该行的所有特征之和得到占比值。
年份   Java   C++   Python   PHP
2015 10      15       7             5
2016 8        10       10           2
2017 12      14       20           0
代码：nor.py
L1范数：先对一个数组中的各个元素取绝对值，再求和
L2范数：先对一个数组中的各个元素取平方值，再求和
4.二值化：将样本矩阵中高于某个给定阈值的元素映射为1，而低于该阈值的元素则映射为0。
代码：bin.py
5.独热编码
1        3           2
7        5           4
1        8           6
7        3           9
1: 10  3: 100  2: 1000
7: 01  5: 010  4: 0100
       8: 001  6: 0010
               9: 0001
1 0 1 0 0 1 0 0 0
0 1 0 1 0 0 1 0 0
1 0 0 0 1 0 0 1 0
0 1 1 0 0 0 0 0 1
代码：ohe.py
6.标签编码：字符串<->数字
代码：lab.py
三、机器学习的基本问题
1.有监督学习：通过已知的输入和输出，寻找它们之间的关系，对未知输出的输入预测其输出。
输入    输出
1         2
5         10
22       44
13       26
17       34
-------------------
19       ? x2 -> 38
1)回归问题：对连续形式的输出进行预测
2)分类问题：对离散形式的输出进行预测
2.无监督学习：在未知输出的前提下，根据输入数据内部的规则进行类别划分。
1)聚类问题
2)成分分析：降低维度，从多个特征中筛选部分最重要的特征
四、线性回归
数据形式：
m个样本n个特征，mxn矩阵   m维向量
/                                        \       /      \
| x11 x12 x13 ... x1n       |       | y1  |
| x21 x22 x23 ... x2n       |       | y2  |
| x31 x32 x33 ... x3n       | -->| y3  |
| ...                                     |       | ...   |
| xm1 xm2 xm3 ... xmn  |       | ym |
\                                        /       \      /
x1 -> y1
x2 -> y2
x3 -> y3
预测函数：kx
预测值：kx1 kx2 kx3
误差值：kx1-y1 kx2-y2 kx3-y3
成本函数：(kx1-y1)^2+(kx2-y2)^2+(kx3-y3)^2
                  -------------------------------------------
                                                 3
什么样的k能使成本函数达到极小值？
k0+k1x(1)+k2x(2)+k3x(3)+...+knx(n)
代码：line.py、load.py
五、岭回归
线性回归的主要问题是对异常值非常敏感。在真实世界的数据收集过程中，经常会遇到错误的度量结果，而线性回归使用的普通最小二乘法，其目标是使平方误差最小化。这时，由于异常值误差的绝对值较大，因此会导致模型参数的明显偏移，降低模型对正常样本的适用度。为了避免这个问题，通过在成本函数中引入正则化项，借助不同样本的阈值权重，削弱少数异常值对回归效果的影响，这就是岭回归。
J(k)+C(k)
代码：rdg.py
六、多项式回归
线性回归模型存在天然的局限，即它只能把输入数据和输出数据的关系表达为线性方程，而通过增加输入样本特征值的高次项，可以得到一个多项式方程，用曲线(面)以更高的精度匹配训练数据。
x1 x2 -> y
y = k0+k1x1+k2x2
y = k0+k1x1+k2x2+k3x1^2+k4x2^2+k5x1x2
   = k0+k1x1+k2x2+k3x3+k4x4+k5x5
代码：poly.py