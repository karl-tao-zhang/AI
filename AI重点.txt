AI重点.txt


1.
过度拟合  噪声引起波动 应该去掉噪声

2.
测试和验证
数据集 --训练集
		\验证集(调参数)
		\测试集
如果用测试集来调整参数再用测试集来测试会出现过拟合
所以还是有验证集比较好

3.
训练模型和
验证模型 是一个互相迭代的过程
不断改善

4.
均值移除  每一项都减去算数平均数

5.
二值化 ,大于为1,小于等于都为0  如果想反过来就取反 等于页为0

6.
独热编码  既要0和1组成又要信息全  独就是一个,热就是1,独热就是只有一个1
还可以规避元素大小值带来的模型偏移

7.
标签编码是按照字典序或者asc码排序,用哪个训练的就用哪个还原,fit这一步会建立编码字典,
用同一个再标签一个直接inverse就不行 必须用同一个有编码的了
并且可以fit 和transform分开用

8.
梯度下降
是一个不断迭代的方式,随机选取一个点然后求梯度最大的反方向乘上一个学习率叶塔,然后找到一个最靠近碗底的一个点.就是损失值最小的一个loss点,相当于最小二乘法找到的回归线的超参数

9.
三步走:
训练器
训练
预测

10.
model.fit(x,y)
如果训练需要x,y 是有监督,只需要x是无监督

11.
model = pl.make_pipeline(
sp.PolynomialFeatures(10),
lm.LinearRegression())
多项式扩展器  注意顺序 先扩展再合成

12. 
会不会过拟合,  就是为了解决过拟合
提升算法是单独使用吗 决策树 都是为了某一方面改善算法 提高泛化能力和熵减值


13.
重叠样本 不可分样本

14.
交叉验证 为什么在训练之前就可以验证?
复制了一份 训练了一次看看效果 然后就扔了

15.
 test_x.append(encoder.transform(data[row]))
 测试时候不要加fit_ 这里要用训练时的字典 不要重新再建

 16.
 学习曲线 返回的是绝对值 ,就是实际训练的条数

 17.
 vc.py没写对
 lc.py也是
 已改正

 18.
 支持向量机  找到所有类别最近点到分界线的距离最大

 19.
 前几个算法并不算出来边界 而支持向量机算出来边界线 这样可以算样本的置信概率
 距离边界线远的置信概率就高


 20.
 怎么预测都是eventA   
 已改正也有别的

 21.
凝聚层次特点是1.不需要任何函数2.可以有连续性
fit 和predict接口合并成了一个 没有中心,不能预测
22.
轮廓系数
接近1 是分的好的  接近-1 是分的差的  接近0 样本重叠
多个聚类整个模型的系数求多个平均值

23.
层次凝聚算法的轮廓系数也这样寻优吗?   不行
有时候红的特别多 是因为聚类样本数量是随机的 如果给固定的 会分的不会偏差特别多

24.
numpy的图标能不能保存出来

25.
最近邻不属于任何一个回归或者聚类 就是寻找最相似的点然后交给别人取用

26.
pipeline经常在哪里用到?
将部件预处理器都串起来,不能自己一个一个找东西,实现自动化处理


27.
KNN
分类,不同类别样本的比例尽量均衡.
回归,只能预测训练数据范围之内或者附近的未知样本.
惰性学习方法,训练阶段不会识别任何模式,速度很快,但是所有的预测都需要涉及大量的距离计算,耗时很长.因此不适于处理规模过于巨大的训练数据集,必须在时间性能和精度性能之前权衡.

28.
数据预处理的东西是因为后来用的特征都是处理好的,清洗了的

29.
词性还原  这些词有的能还原成单数和原型但是还需要一个个对比,不能和一起吗
这个只是为了让人能来看懂 机器只是需要提取主干部分,然后分析词频


非线性多元方程组能不能用python写?
计算机一般解析的方程比较难算,通过迭代和插值方法求


30.
贝叶斯 tfidf预测时候用cv.transform()不能用fit_transform

31.
sigs每一列是一个声道,每一行是一个采样值

32.
eq.py有点问题 维度不对

33.
自己安装cv2
和hmmlearn

34.
降维没讲看一下

35.
neurolab接口 高层
TensorFlow接口 底层

